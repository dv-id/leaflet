<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>8)</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
        integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Alegreya:ital,wght@0,400..900;1,400..900&family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&family=Noto+Sans:ital,wght@0,100..900;1,100..900&family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&family=Ultra&family=VT323&display=swap"
        rel="stylesheet">
</head>

<body>

    <nav class="navbar fixed-top container">
        <a class="navbar-brand" href="/index.html">about</a>
        <a class="navbar-brand" href="/books.html">books</a>
        <a class="navbar-brand" href="/essays.html">essays</a>
    </nav>

    <div class="container mt-5 d-flex align-items-center justify-content-center">
        <div class="row vh-100">
            <div class="col-12">
                <h1 id="heading" class="alegreya">
                </h1>

                <p>
                    Cooperation emerges when there is a high likelihood of repeated interactions between the
                    players in the future – we will call it δ – and it yields some benefits later on – reciprocity.
                    If you interact with the same player in the future you can reason that if you defect him in the
                    first interaction he won’t cooperate with you in the next round. What if you need somebody to
                    cooperate with? For example you won't be able to hunt down a large animal by yourself, you
                    would only hunt small animals. That's the only thing you can pull off on your own. But
                    imagine that you have to survive a cold winter and the only way to do it is to hunt large
                    animals for their fur to stay warm when it’s freezing. You can’t do it only by yourself. You
                    need to cooperate with others to hunt the animal down. Everyone would be better off if they
                    got themselves to cooperate. Without cooperation they would not survive winter.
                </p>
                <p>
                    We can spot cooperation everywhere around us in our everyday lives. Business partners are
                    nice to each other because they are helping each other make money and expect to do so in
                    the future. People behave nicely in their neighborhoods because the interactions between
                    neighbors are likely to be long-term and you don’t want to make enemies in a place you
                    won’t leave for a while (Whenever a new family moves to a new neighborhood in an
                    american movie, they usually go around with gifts to their neighbors to make a good first
                    impression). The existence of money relies on cooperation. What if you could not exchange
                    money for goods and services in the future? You would not exchange anything for money in
                    the first place. It would be worthless.
                </p>
                <p>
                    We are going to go through two case studies on vampire bats by Gerald S. Wilkinson and on
                    soldiers during World War I by Robert Axelrod to conclude that our two main principles: high
                    δ and reciprocity are at the core of interactions between players in these case studies.
                    “Once the US and the USSR know that they will be dealing with each other indefinitely, the
                    necessary preconditions for cooperation will exist.... The foundation of cooperation is not
                    really trust, but the durability of the relationship."
                    — Robert Axelrod
                </p>
                <p>
                    In an utopian world we could replace the US and USSR with every other state on Earth to
                    embrace all potential gain from the cooperation of nations and live peacefully forever after,
                    since we all share the same planet together and likely will be in the future.
                    First of all we are going to use the famous Prisoners dilemma model to see how two players
                    make strategic decisions in a one-shot interaction. The players choose whether to cooperate
                    or defect. Cooperation is costly, but it benefits the other player by more than it costs – c < b.
                        Thus it would be better if both of them cooperate, but there is a catch. When they are deciding
                        what strategy to choose, they are always better off defecting. Regardless of what the other
                        does, it pays off more to defect. This is called a dominant strategy in Game theory jargon. So
                        looking at the interaction from an individual's point of view they both defect, but that's worse
                        than the outcome that could be accomplished by cooperation. Yet people cooperate all the time.
                        They help each other, they care for each other. Why is that? The answer lies in repeated
                        interactions. There’s no reason to cooperate when you interact just once with the other player
                        and never see them again. But people don't really interact exactly once with each other. There
                        are situations all around us where you have to deal with the same people over and over again.
                        How does that change the interactions?
                    </p>
                        <p>
                        To find out, let's try to see how the repeated prisoners'
                        dilemma works. In each interaction, both players play the same prisoner’s dilemma – they choose
                        to cooperate (C) or defect (D). Then they learn what the other did and play another round. Every
                        additional round will happen with a probability δ (or you can think about it as a discounting
                        factor that values future rounds less than the current round). If the interactions are likely to
                        be repeated the δ is closer to 1. Imagine that the interaction happens between two business
                        people. If the benefits of cooperation exceed the costs – b> c – and the δ is high – close to
                        one – then
                        they will both benefit from cooperation. What if someone decides to deviate from cooperation
                        and suddenly defect the other player. He would be incentivized to do that because he could
                        gain without paying the cost. What should the betrayed do in the next round?
                        </p>
                        <p>
                        We can come up with many different strategies for the repeated prisoner's dilemma. Players
                        can cooperate in every round no matter what happened in previous interactions – ALLC
                        strategy. Or they can defect everytime – ALLD. They can even make some conditions in
                        their strategies like: cooperate in the first round and then from that point forward, simply
                        copy
                        what the other did in the previous round – Tit-for-tat (TFT). Cooperate in the first round, then
                        continue to cooperate as long as neither of you has defected, if anyone defected you always
                        defect from that point on – Grim trigger. And so on. Robert Axelrod organized a tournament
                        of different strategies submitted by experts. Each of the strategies were paired off against
                        each other to see, which would do best. The winner of all complex strategies was a simple
                        Tit-for-tat strategy – reciprocity strategy. A second round was also won by the same strategy.
                        From all of the interactions he concluded some principles for a successful strategy. Those
                        were:
                        Avoidance of unnecessary conflict by cooperating as long as the other player does.
                        Provocability in the face of an uncalled-for defection by the other.
                        Forgiveness after responding to a provocation and clarity of behavior so that the
                        other player can recognize and adapt to your pattern of action.
                    </p>
                    <p>
                        So far we have come to a few main principles that have to be present in order for
                        cooperation to emerge – cooperation has to benefit more than it costs, δ has to be high,
                        reciprocity has to be present. Let’s see if we can spot these principles in action in two case
                        studies – one regarding the fighting in trenches during the World War I by Robert Axelrod
                        and the other on food sharing in Vampire bats by Gerald S. Wilkinson.
                        In the Evolution of Cooperation (title), Robert Axelrod provided an example which shows that
                        cooperation can arise when δ is high even in the worst environment: the trenches of World
                        War I. Because of the technology of the time, the best way to get over a trench was to go
                        around it. Thus the opposing sides both dug trenches all the way from the North Atlantic in
                        Belgium to the Alps in the south. This meant that the war was going to be fought in the
                        trenches for a long time and that the same soldiers were going to face off against the same
                        soldiers for a period of time – the δ was high. This opened the door for cooperation. Soldiers
                        stopped fighting for real, they faked fighting by sniping and bombarding the same places
                        over and over again to make it totally obvious for the enemies that they were not planning to
                        hurt them and expecting to benefit from the same treatment. There are even records of
                        soldiers apologizing for accidentally firing a round at a place and time that wasn’t expected.
                        When soldiers shot unexpectedly or for real, the other side didn’t hold back and fired way
                        harder back to show them that they should not do that again – punished them for breaking
                        cooperation. This act of punishment seem to abide by the quote:
                        “If an injury has to be done to a man it should be so severe that his
                        vengeance need not be feared.”
                        – Niccolo Machiavelli, The Prince
                        The cooperation ended when the commanders on both sides noticed and made sure that no
                        unit of soldiers faced the enemies for a long period of time – thus making the δ low.
                    </p>
                    <p>
                        Let’s now find out if it's more likely for players to cooperate with those who have cooperated
                        with them in the past – reciprocity. Gerald S. Wilkinson studied Vampire bats that are prone
                        to starve if they hunt unsuccessfully for a few nights in a row, but they seem to be highly
                        thankful to the other vampire bats that feed them in times of need. When bats return from a
                        successful hunt, they will give some of the blood in its mouth to the bats that were
                        unsuccessful. Wilkinson showed that a previously starving bat was eager to repay the favor
                        to the bat that helped him when he needed it the most – high reciprocity. This study shows
                        us that reciprocity is needed for cooperation to emerge. High δ was also present in this study
                        – a lot of vampire bats had been in the same group for a long time.
                    </p>
                    <p>
                        We’ve seen our principles for cooperation embraced by humans and even by bats. What if in
                        these interactions there was somebody who was gaining the benefits and not paying any
                        cost? In order to sustain cooperation these so called free-riders have to be punished for
                        reaping the benefits without paying the costs. Otherwise the cooperation would not be stable
                        and they would benefit by deviating. The punishment for not cooperating makes it less worth
                        it for them. If free-riders go unpunished, the cooperative individuals also tend to stop
                        cooperating. What if, in a group, the free-riders get punished but it is costly for the
                        punishers
                        to punish. Why would they punish the free-riders in the first case, when they could rely on
                        the others to do it for them and reap the benefits anyway?
                        david nikel 3 political science
                        For the group to sustain cooperation it has to punish the free-riders and also punish those
                        who have not been punished even though they should have had. This second order
                        punishment motivates the punishers to punish the free-riders. So for cooperation to be
                        sustained another principle plays a significant role – punishment of the free-riders and
                        punishment of those who didn't punish the free-rider but should have had. The δ still has to
                        be high in order for the punishment to have an effect. If it is not, the punisher would punish
                        the free-rider never to interact with him again and thus would not reap any benefits from this
                        punishment which is costly to him. This principle of a second order punishment seems to be
                        similar to Jeremy Bentham’s Panopticon in a sense that you would rather punish the
                        free-rider than to get punished by others for not doing so, even though your inaction may be
                        unwitnessed by others. Just the possibility of the punishment motivates you to punish the
                        free-rider.
                    </p>
                    <p>
                        In summary, to sustain cooperation there must be a high likelihood of repeated interaction,
                        past behavior must be highly observable. The δ must be high. Cooperating today must yield
                        some future benefit, like others being more likely to cooperate with you later – reciprocity.
                        Cooperative behavior needs to be conditional – people can’t just cooperate without a reason,
                        as they might with someone they care about unconditionally like a family member just to
                        improve his or her wellbeing. The foundation of cooperation is not really trust, but the
                        durability of the interaction. If the conditions are right, the players come to cooperation by
                        trial-and-error, learning what strategy comes with the biggest payoff or through imitation of
                        other players who are successful. Even evolution helps us by eliminating the unsuccessful
                        strategies and leaving us with the successful ones. If the conditions for cooperation are right
                        it will emerge no matter what.
            
                </p>
            </div>
        </div>
    </div>
    <script src="https://unpkg.com/typed.js@2.1.0/dist/typed.umd.js"></script>
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.7/dist/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
    <script>
        var typed = new Typed('#heading', {
          strings: ["Under what conditions can cooperation emerge from repeated interactions?"],
          typeSpeed: 50,
          showCursor: false
        });
    </script>
</body>

</html>